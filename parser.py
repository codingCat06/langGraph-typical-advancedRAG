"""
Parser - PDF íŒŒì‹± ìš”ì²­ ë° ìƒíƒœ ê´€ë¦¬
ë ˆê±°ì‹œ/ì‹ ê·œ store.json í¬ë§· ëª¨ë‘ ì§€ì›
"""

import json
import time
import hashlib
from typing import Dict, Any, Optional, List

import requests

from settings import (
    API_MARKER_ENDPOINT,
    STORE_FILE,
    PARSED_DIR,
    get_check_url
)


# =============================================================================
# Store Management (í˜¸í™˜ì„± ë ˆì´ì–´)
# =============================================================================

def load_store() -> Dict[str, Any]:
    """ë¡œì»¬ ìŠ¤í† ì–´ ë¡œë“œ"""
    if STORE_FILE.exists():
        with open(STORE_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    return {}


def save_store(store: Dict[str, Any]) -> None:
    """ë¡œì»¬ ìŠ¤í† ì–´ ì €ì¥"""
    with open(STORE_FILE, "w", encoding="utf-8") as f:
        json.dump(store, f, ensure_ascii=False, indent=2)


def get_url_hash(url: str) -> str:
    """URLì˜ ì§§ì€ í•´ì‹œ ìƒì„±"""
    return hashlib.md5(url.encode()).hexdigest()[:12]


def get_doc_entries(store: Dict[str, Any]) -> Dict[str, Dict[str, Any]]:
    """
    ë¬¸ì„œ í•­ëª©ë§Œ ì¶”ì¶œ (ë ˆê±°ì‹œ/ì‹ ê·œ í¬ë§· í˜¸í™˜)
    Returns: {url: data} ë”•ì…”ë„ˆë¦¬
    """
    entries = {}
    
    # ì‹ ê·œ í¬ë§·: documents í‚¤ ì•„ë˜ì— ì €ì¥
    if "documents" in store:
        for doc_id, data in store.get("documents", {}).items():
            if isinstance(data, dict):
                url = data.get("source_url", doc_id)
                entries[url] = data
    
    # ë ˆê±°ì‹œ í¬ë§·: URLì´ ì§ì ‘ í‚¤ë¡œ ì €ì¥
    for key, data in store.items():
        if key in ("documents", "cache", "events", "_legacy_migrated"):
            continue
        if isinstance(data, dict) and key.startswith("http"):
            entries[key] = data
    
    return entries


def update_doc_entry(store: Dict[str, Any], url: str, updates: Dict[str, Any]) -> None:
    """
    ë¬¸ì„œ í•­ëª© ì—…ë°ì´íŠ¸ (ë ˆê±°ì‹œ/ì‹ ê·œ í¬ë§· í˜¸í™˜)
    """
    # ë ˆê±°ì‹œ: ë£¨íŠ¸ ë ˆë²¨ì— ìˆìœ¼ë©´ ê·¸ê³³ ì—…ë°ì´íŠ¸
    if url in store:
        store[url].update(updates)
        return
    
    # ì‹ ê·œ: documents ì•„ë˜ì—ì„œ ì°¾ê¸°
    if "documents" in store:
        for doc_id, data in store["documents"].items():
            if data.get("source_url") == url:
                store["documents"][doc_id].update(updates)
                return
    
    # ëª» ì°¾ìœ¼ë©´ ë ˆê±°ì‹œ ë°©ì‹ìœ¼ë¡œ ì¶”ê°€
    if url not in store:
        store[url] = {}
    store[url].update(updates)


# =============================================================================
# Upload
# =============================================================================

def upload(file_url: str, output_format: str = "markdown") -> Optional[str]:
    """
    PDF URLì„ APIì— ì „ì†¡í•˜ì—¬ íŒŒì‹± ìš”ì²­
    
    Returns:
        request_id if successful, None otherwise
    """
    store = load_store()
    entries = get_doc_entries(store)
    
    # ì¤‘ë³µ ì²´í¬
    if file_url in entries:
        print(f"[CACHE] ì´ë¯¸ ìš”ì²­í•œ PDFì…ë‹ˆë‹¤")
        print(f"        Status: {entries[file_url].get('status')}")
        return entries[file_url].get("request_id")
    
    print(f"[UPLOAD] PDF íŒŒì‹± ìš”ì²­ ì¤‘...")
    
    data = {
        "file_url": file_url,
        "output_format": output_format
    }
    
    try:
        response = requests.post(API_MARKER_ENDPOINT, data=data, timeout=30)
        result = response.json()
        
        if result.get("success"):
            request_id = result.get("request_id")
            
            # ë ˆê±°ì‹œ ë°©ì‹ìœ¼ë¡œ ì €ì¥ (í˜¸í™˜ì„±)
            store[file_url] = {
                "request_id": request_id,
                "status": "pending",
                "parsed_file": None,
                "vectorized": False,
                "uploaded_at": time.strftime("%Y-%m-%d %H:%M:%S")
            }
            save_store(store)
            
            print(f"[SUCCESS] ìš”ì²­ ì ‘ìˆ˜ë¨")
            print(f"          Request ID: {request_id}")
            return request_id
        else:
            print(f"[ERROR] API í˜¸ì¶œ ì‹¤íŒ¨: {result.get('error')}")
            return None
            
    except requests.exceptions.Timeout:
        print("[TIMEOUT] ì„œë²„ê°€ ê¹¨ì–´ë‚˜ëŠ” ì¤‘ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤ (Cold Start)")
        print("          ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.")
        return None
    except Exception as e:
        print(f"[ERROR] {e}")
        return None


# =============================================================================
# Status
# =============================================================================

def status() -> None:
    """
    ìƒíƒœ í™•ì¸ (vectorizedëœ í•­ëª© ì œì™¸)
    pending â†’ success ìë™ fetch
    """
    store = load_store()
    entries = get_doc_entries(store)
    
    if not entries:
        print("[INFO] ë“±ë¡ëœ PDFê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # vectorizedê°€ ì•„ë‹Œ í•­ëª©ë§Œ
    not_vectorized = {url: data for url, data in entries.items()
                      if not data.get("vectorized", False)}
    
    if not not_vectorized:
        print("[INFO] ëª¨ë“  PDFê°€ vectorized ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return
    
    print(f"\n{'='*50}")
    print(f"PDF ìƒíƒœ ({len(not_vectorized)}ê°œ)")
    print(f"{'='*50}\n")
    
    for url, data in not_vectorized.items():
        current_status = data.get("status", "unknown")
        request_id = data.get("request_id")
        
        # pendingì´ë©´ APIì—ì„œ í™•ì¸
        if current_status == "pending" and request_id:
            print(f"ğŸ”„ Checking: {url[:40]}...")
            
            try:
                check_url = get_check_url(request_id)
                response = requests.get(check_url, timeout=30)
                result = response.json()
                api_status = result.get("status")
                
                if api_status == "complete" and result.get("success"):
                    # íŒŒì‹± ê²°ê³¼ ì €ì¥
                    markdown = result.get("markdown", "")
                    url_hash = get_url_hash(url)
                    parsed_file = PARSED_DIR / f"{url_hash}.md"
                    
                    with open(parsed_file, "w", encoding="utf-8") as f:
                        f.write(markdown)
                    
                    update_doc_entry(store, url, {
                        "status": "success",
                        "parsed_file": str(parsed_file),
                        "page_count": result.get("page_count"),
                        "fetched_at": time.strftime("%Y-%m-%d %H:%M:%S")
                    })
                    
                    current_status = "success"
                    print(f"   âœ… Success!")
                    
                elif api_status == "complete" and not result.get("success"):
                    update_doc_entry(store, url, {
                        "status": "failed",
                        "error": result.get("error")
                    })
                    current_status = "failed"
                    print(f"   âŒ Failed")
                else:
                    print(f"   â³ Processing...")
                    
            except Exception as e:
                print(f"   âš ï¸ Check failed: {e}")
        
        # ìƒíƒœ ì¶œë ¥
        icon = {"pending": "â³", "success": "âœ…", "failed": "âŒ"}.get(current_status, "â“")
        print(f"{icon} [{current_status.upper()}] {url[:50]}...")
        print()
    
    save_store(store)
